Time: 22.11.2023 12:55:42
Accuracy: 0.3731736274681295

Optimizer: Adam
Learning Rate: 0.001
Scheduler: False
Weight decay: 0
Smoothing: 0
Batch size: 64


Time: 22.11.2023 12:59:20
Accuracy: 0.4245773836951257

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 13:51:33
Accuracy: 0.41819853892085196

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 14:43:47
Accuracy: 0.4226524297374358

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 15:36:02
Accuracy: 0.4127072112066028

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 16:28:18
Accuracy: 0.42926248169548253

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 17:20:28
Accuracy: 0.4307241521934662

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 18:12:45
Accuracy: 0.4471444914038104

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 19:05:01
Accuracy: 0.43496884981805184

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 19:57:20
Accuracy: 0.4409003893065243

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 20:49:36
Accuracy: 0.4362824855607911

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 21:41:48
Accuracy: 0.43790669514683217

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 22:34:04
Accuracy: 0.4155924390349045

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 22.11.2023 23:26:20
Accuracy: 0.4218275776219955

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 00:18:34
Accuracy: 0.4368501078404189

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 01:10:50
Accuracy: 0.43549659445147704

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 02:03:02
Accuracy: 0.4318516671652532

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 02:55:25
Accuracy: 0.43517204687880845

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 03:47:44
Accuracy: 0.42681216818934614

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 04:40:03
Accuracy: 0.4208642748369549

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 05:32:21
Accuracy: 0.43926235207579706

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 06:24:38
Accuracy: 0.43292564428398894

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 07:16:59
Accuracy: 0.41597703311247625

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 08:09:17
Accuracy: 0.43666326262255134

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 09:01:32
Accuracy: 0.4243128176708833

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 09:58:42
Accuracy: 0.4327420912354324

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 10:52:34
Accuracy: 0.41888328570740885

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 11:46:29
Accuracy: 0.43811294005282875

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 12:39:24
Accuracy: 0.41707042924538906

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 13:31:34
Accuracy: 0.4294916274323084

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 14:23:58
Accuracy: 0.4217445096831013

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 15:16:15
Accuracy: 0.43387284094828993

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 16:08:33
Accuracy: 0.4264622445563615

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 17:00:54
Accuracy: 0.4280427398852683

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 17:53:09
Accuracy: 0.43108788130996695

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 18:45:27
Accuracy: 0.42183520991621076

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 19:37:42
Accuracy: 0.4256115916534114

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 20:29:55
Accuracy: 0.42811649066942253

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 21:22:11
Accuracy: 0.42367486484751854

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 22:14:23
Accuracy: 0.44703972132452335

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 23:06:41
Accuracy: 0.43828990097322795

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 23.11.2023 23:58:57
Accuracy: 0.4352029347220946

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 00:51:15
Accuracy: 0.4343203162497383

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 01:43:32
Accuracy: 0.43187762361371684

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 02:35:47
Accuracy: 0.4201513784746287

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 03:28:01
Accuracy: 0.4262052674338869

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 04:20:13
Accuracy: 0.4264758399371833

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 05:12:23
Accuracy: 0.4305845902970836

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 06:04:40
Accuracy: 0.42690797465519414

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 06:56:54
Accuracy: 0.4363153049781322

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 07:49:07
Accuracy: 0.4396789780370691

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 08:41:17
Accuracy: 0.4269206508867932

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 09:33:26
Accuracy: 0.4376911848853494

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 10:25:37
Accuracy: 0.43827792233505686

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 24.11.2023 11:17:47
Accuracy: 0.41387424637975423

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 11:38:22
Accuracy: 0.43174024143090134

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 12:30:30
Accuracy: 0.42704587292940493

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 13:22:37
Accuracy: 0.43513029052891083

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 14:14:48
Accuracy: 0.41982899849074345

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 15:06:53
Accuracy: 0.42726892377868153

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 15:59:01
Accuracy: 0.4397453220381615

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 16:51:19
Accuracy: 0.42885032014706825

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 17:43:29
Accuracy: 0.42002263289963476

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 18:35:40
Accuracy: 0.4308304232176692

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 19:27:51
Accuracy: 0.43184061354177594

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 20:20:00
Accuracy: 0.4192989176015364

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 21:12:12
Accuracy: 0.42958840878295723

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 22:04:26
Accuracy: 0.40853826367352675

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 22:56:39
Accuracy: 0.43278287408605065

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 27.11.2023 23:48:58
Accuracy: 0.42788047588607997

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 00:41:11
Accuracy: 0.4165092307581778

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 01:33:27
Accuracy: 0.4390087273526115

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 02:25:43
Accuracy: 0.45949158247948246

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 03:18:04
Accuracy: 0.4286056772671503

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 04:10:20
Accuracy: 0.44816559558920865

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 05:02:38
Accuracy: 0.41220099089822315

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 05:54:53
Accuracy: 0.43321630323879323

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 06:47:10
Accuracy: 0.42010257169586873

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 07:39:22
Accuracy: 0.44398807943453883

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 08:31:32
Accuracy: 0.4227861219591512

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 09:23:44
Accuracy: 0.4208439409857829

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 10:15:57
Accuracy: 0.4146749663065928

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 11:08:06
Accuracy: 0.4346874317590904

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 12:00:15
Accuracy: 0.42709361026298537

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 12:52:34
Accuracy: 0.41573549279040456

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 13:44:46
Accuracy: 0.4287132205665093

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 14:36:57
Accuracy: 0.42159746371640633

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 15:29:11
Accuracy: 0.41913327388377836

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 16:21:22
Accuracy: 0.4281235328166466

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 17:13:33
Accuracy: 0.44209556709823894

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 18:05:49
Accuracy: 0.43095520321880104

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 18:58:02
Accuracy: 0.4371580291275012

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 19:50:13
Accuracy: 0.4177093590053783

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 20:42:24
Accuracy: 0.4314629368500076

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 21:34:37
Accuracy: 0.4374161781265879

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 22:26:47
Accuracy: 0.4214587511864146

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 28.11.2023 23:18:59
Accuracy: 0.4313297230508005

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 00:11:12
Accuracy: 0.4185388504425478

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 01:03:25
Accuracy: 0.4222618699370493

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 01:55:38
Accuracy: 0.4304613628855547

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 02:47:47
Accuracy: 0.42264170906098525

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 03:39:58
Accuracy: 0.4232629238314286

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 04:32:16
Accuracy: 0.4322460789937005

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 05:24:34
Accuracy: 0.42321429633575425

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 06:16:49
Accuracy: 0.4291865073986164

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 07:09:11
Accuracy: 0.42753299657886334

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 08:01:25
Accuracy: 0.4263029078738939

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 08:53:40
Accuracy: 0.4290242515650662

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


Time: 29.11.2023 09:45:46
Accuracy: 0.43108535566913964

Optimizer: Adam
Learning Rate: 0.0001
Scheduler: False
Weight decay: 0.001
Smoothing: 0
Batch size: 32


