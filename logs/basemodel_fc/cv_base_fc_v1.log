Created: 13.09.2023 17:53:35
Model version: base_fc_v1
Path: saved_models/base_fc_v1.pth
Run name: batch32_lr-0d001smooth0d03optim-SGD_wdecay0_sch-False_mom0
Accuracy: 0.26193722710182865

Fold 1: 0.23188471068255553.
Fold 2: 0.27103034689609645.
Fold 3: 0.2820051039773831.
Fold 4: 0.23824049939880643.
Fold 5: 0.28652547455430194.

Hyperparameters:
Optimizer: SGD
Momentum: 0
Learning rate: 0.001
Weight decay: 0
Used CrossEntropyLoss with label smoothing 0.0331
Balanced classes
Train batch size: 32
Validation batch size: 5


--------------------------Script of the model can be seen below.---------------------------
import torch
import torch.nn as nn
import torch.nn.functional as F
import os

model_version=os.path.basename(__file__).split(".")[0]

class base_fc(nn.Module):
    def __init__(self):
        super(base_fc, self).__init__()
        # YOUR CODE HERE
        self.dropout=nn.Dropout(0.3) #changed from 0.2->0.3 1.6.2022
        self.fc1=nn.Linear(84,200)#150) 
        self.bn1 = nn.BatchNorm1d(200)
        self.fc2=nn.Linear(200,120)
        self.bn2 = nn.BatchNorm1d(120)
        self.fc3=nn.Linear(120,8)
        self.fc4=nn.Linear(120,1)
        self.sigmoid=nn.Sigmoid()
        

    def forward(self, x):
        """
        Args:
          x of shape (batch_size, 84): Input sequences.
        
        Returns:
          y of shape (batch_size, 8): Outputs of the network.
        """
        
        
        y=self.fc1(x)
        y=self.dropout(y)
        y=F.relu(y)
        y=self.bn1(y)
        
        y=self.fc2(y)
        y=self.dropout(y)
        y=F.relu(y)
        y=self.bn2(y)
        
        y=self.fc3(y)
        
        return y
-------------------------------------------------------------------------------------------



------------------------------Created input matrices with script:------------------------------
import numpy as np
import torch


def get_norm_values(file):
    channel_numbers=dict()
    previous_id=None
    with open(file, 'r') as fr:
        for line in fr:
            if line.startswith('#'):
                if line.startswith("#ID:"):
                        if line.strip()!=previous_id:
                            previous_id=line.strip()
                            channel=0
                        else:
                            channel+=1
                continue
            if not channel in channel_numbers:
                channel_numbers[channel]=list()
            numbers=line.strip().split(',')
            channel_numbers[channel].append(float(numbers[17]))
    mins=dict()
    maxes=dict()
    for channel in channel_numbers:
        mins[channel]=min(channel_numbers[channel])
        maxes[channel]=max(channel_numbers[channel])
    return mins, maxes


def parse_matrices(file, classes):
    mins, maxes = get_norm_values(file)
    bases={'A': 0, 'C': 1, 'G': 2, 'T': 3}
    row=0
    df_target=np.empty((1,1,1))
    first_2d=True
    first_3d=True
    first_4d_input=True
    first_df_input=True
    new_sampleid=True
    previous_id=None
    single_class=list()
    target=list()
    row_list=list()
    with open(file, 'r') as fr:
        for line in fr:
            if line.startswith('#'):
                if line.startswith("#ID:"):
                    if previous_id==None or line.strip()!=previous_id:
                        channel=0
                        if previous_id!=None:
                            if first_df_input:
                                df_input=temp_2d
                                first_df_input=False
                            else:
                                df_input=np.concatenate((df_input, temp_2d), axis=0)
                        previous_id=line.strip()
                        new_sampleid=True
                        first_2d=True
                    else:
                        channel+=1
                        
                if line.startswith('#REF:'):
                    ref=line[6]
                elif line.startswith('#ALT:') and new_sampleid:
                    alt=line[6]
                    target.append(torch.tensor(classes[ref+alt]))
                    new_sampleid=False
                continue
            numbers=line.strip().split(',')
            important_feature=(float(numbers[17])-mins[channel])/(maxes[channel]-mins[channel])
            row_in_array=np.array(important_feature).reshape(1,-1)
            if first_2d:
                temp_2d=row_in_array
                first_2d=False
            else:
                temp_2d=np.concatenate((temp_2d, row_in_array), axis=1)

    if not first_2d:
        df_input=np.concatenate((df_input, temp_2d), axis=0)
    return torch.Tensor(df_input), torch.tensor(target,dtype=torch.long)
-------------------------------------------------------------------------------------------



------------------------------Computed accuracies with script:-----------------------------
import torch

def count_f_scores(tp,fp,tn,fn):
    if (tp+fp)==0:
        precision=0
    else:
        precision=tp/(tp+fp)
    if tp+fn==0:
        recall=0
    else:
        recall=tp/(tp+fn)
    if precision==0 and recall==0:
        f1=f2=0
    else:
        f1=2*(precision*recall)/(precision+recall)
        f2=5*(precision*recall)/(4*precision+recall)
    return f1, f2, precision, recall

def count_pred_types(ftp, ftn, tp,fp,tn,fn, labels, predicted, sequences):
    for label, prediction, sequence in zip(labels, predicted, sequences):
        #if label in [0,5,10,15]:
        #if label==4:
        if label in [1,7]:
        #if label in [4,5,6,7]:
            if label==prediction:
                tn+=1
            else:
                fp+=1
                #if prediction in [0,5,10,15]:
                if prediction in [1,7]:
                #if prediction in [4,5,6,7]:
                #if prediction==4:
                    ftn+=1
        else:
            if label==prediction:
                tp+=1
            else:
                fn+=1
                #if prediction!=4:
                #if prediction not in [0,5,10,15]:
                if prediction not in [1,7]:
                #if not prediction in [4,5,6,7]:
                    #for i in range(4):
                    #    if sequence[0, i,16]==1:
                    #        ref=i
                    #if prediction!=i:
                     #   ftn+=1
                    ftp+=1
    return tp,fp,tn,fn,ftn, ftp

def compute_accuracy(device, net, dataloader, criterion, datatype, verbose, cv):
    net.eval()
    correct = 0
    total = 0
    tp=fp=tn=fn=ftn=ftp=0
    number_of_classes=8
    correct_per_class=[0 for i in range(number_of_classes)]
    total_per_class=[0 for i in range(number_of_classes)]
    with torch.no_grad():
        tot_loss=0
        tot_items=0
        for sequences, labels in dataloader:
            sequences, labels = sequences.to(device), labels.to(device)
            outputs = net(sequences)
            _, predicted = torch.max(outputs.data, 1)
            for label, prediction in zip(labels, predicted):
                correct_per_class[label]+=(label==prediction).item()
                total_per_class[label]+=1
            if cv:
                tot_loss+=criterion(outputs,labels).item()
                tot_items+=len(labels)
            if verbose:
                tp,fp,tn,fn, ftn, ftp = count_pred_types(ftp, ftn, tp,fp,tn,fn, labels, predicted, sequences)
        if cv:
            tot_loss/=tot_items
        for i in range(number_of_classes):
            correct+=(correct_per_class[i]/total_per_class[i])/number_of_classes
        #f1, f2, precision, recall = count_f_scores(tp,fp,tn,fn)
        #f1_fake, f2_fake, fake_precision, fake_recall = count_f_scores((tp+ftp),(fp-ftn),(tn+ftn),(fn-ftp))
        if verbose:
            f1, f2, precision, recall = count_f_scores(tp,fp,tn,fn)
            f1_fake, f2_fake, fake_precision, fake_recall = count_f_scores((tp+ftp),(fp-ftn),(tn+ftn),(fn-ftp))
            tn_tnfp=tn/(tn+fp) if tn+fp>0 else 0
            fake_tpftp_tpftpfn=(tp+ftp)/(tp+ftp+fn) if (tp+ftp+fn)>0 else 0
            fake_tnftn_tnftnfp=(tn+ftn)/(tn+ftn+fp) if (tn+ftn+fp)>0 else 0
            print('\n',datatype)
            print("TP:",tp,". FN:",fn, "TP/(TP+FN):",recall,"TN:",tn,"FP:",fp,"TN/(TN+FP):",tn_tnfp,
                  "Wrong positive class predicted:",ftp, "Wrong negative class predicted:",ftn)
            print("Fake F1-score:",f1_fake,". Fake F2-score:",f2_fake)
            print("Fake TP/(TP+FN):",fake_tpftp_tpftpfn,"Fake TN/(TN+FP)",fake_tnftn_tnftnfp)
            print("Fake precision:",fake_precision,"Fake recall:",fake_recall)
    #return correct / total, tot_loss, f1, f2
    return correct, tot_loss #, f1, f2, precision, recall, f1_fake, f2_fake, fake_precision, fake_recall
-------------------------------------------------------------------------------------------
